{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 1 (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('mnist_train.csv')\n",
    "test_data = pd.read_csv('mnist_test.csv')\n",
    "train_data.isnull().sum().head(10)\n",
    "round(train_data.drop('label', axis=1).mean(), 2)\n",
    "y = train_data['label']\n",
    "\n",
    "## Dropping the variable 'label' from X variable \n",
    "X = train_data.drop(columns = 'label')\n",
    "X = X/255.0\n",
    "test_data = test_data/255.0\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "X_scaled = scale(X)\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size = 0.3, train_size = 0.2 ,random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear model\n",
    "\n",
    "model_linear = SVC(kernel='linear')\n",
    "model_linear.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "y_pred = model_linear.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9103333333333333 \n",
      "\n",
      "[[1719    0   10    5    3   16   12    1    6    0]\n",
      " [   1 1951   11    5    5    4    0    3   11    1]\n",
      " [  11   26 1676   30   23    5   23   19   17    1]\n",
      " [  10    4   47 1627    4   66    5   19   42   10]\n",
      " [   4    8   21    1 1658    5   14    6    5   50]\n",
      " [  21    9   19   87   12 1423   30    1   39   11]\n",
      " [  20    7   23    1   14   20 1666    2    4    0]\n",
      " [   7   13   19   16   31    4    2 1774    5   93]\n",
      " [  25   44   49   54   12   58   18   11 1436   17]\n",
      " [   4   11   19   23   90    9    1   69   20 1456]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# accuracy\n",
    "print(\"accuracy:\", metrics.accuracy_score(y_true=y_test, y_pred=y_pred), \"\\n\")\n",
    "\n",
    "# cm\n",
    "print(metrics.confusion_matrix(y_true=y_test, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 2 (Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nishit/.conda/envs/venv/lib/python3.7/site-packages/ipykernel_launcher.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/nishit/.conda/envs/venv/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: divide by zero encountered in log\n",
      "/home/nishit/.conda/envs/venv/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000000\n",
      "         Iterations: 1\n",
      "         Function evaluations: 5\n",
      "         Gradient evaluations: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nishit/.conda/envs/venv/lib/python3.7/site-packages/ipykernel_launcher.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/nishit/.conda/envs/venv/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: divide by zero encountered in log\n",
      "/home/nishit/.conda/envs/venv/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in multiply\n",
      "/home/nishit/.conda/envs/venv/lib/python3.7/site-packages/ipykernel_launcher.py:20: RuntimeWarning: divide by zero encountered in log\n",
      "/home/nishit/.conda/envs/venv/lib/python3.7/site-packages/ipykernel_launcher.py:20: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.023979\n",
      "         Iterations: 50\n",
      "         Function evaluations: 101\n",
      "         Gradient evaluations: 101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nishit/.conda/envs/venv/lib/python3.7/site-packages/ipykernel_launcher.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/nishit/.conda/envs/venv/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: divide by zero encountered in log\n",
      "/home/nishit/.conda/envs/venv/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in multiply\n",
      "/home/nishit/.conda/envs/venv/lib/python3.7/site-packages/ipykernel_launcher.py:20: RuntimeWarning: divide by zero encountered in log\n",
      "/home/nishit/.conda/envs/venv/lib/python3.7/site-packages/ipykernel_launcher.py:20: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.069625\n",
      "         Iterations: 50\n",
      "         Function evaluations: 97\n",
      "         Gradient evaluations: 97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nishit/.conda/envs/venv/lib/python3.7/site-packages/ipykernel_launcher.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/nishit/.conda/envs/venv/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: divide by zero encountered in log\n",
      "/home/nishit/.conda/envs/venv/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.088793\n",
      "         Iterations: 50\n",
      "         Function evaluations: 99\n",
      "         Gradient evaluations: 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nishit/.conda/envs/venv/lib/python3.7/site-packages/ipykernel_launcher.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/nishit/.conda/envs/venv/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: divide by zero encountered in log\n",
      "/home/nishit/.conda/envs/venv/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.047835\n",
      "         Iterations: 50\n",
      "         Function evaluations: 102\n",
      "         Gradient evaluations: 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nishit/.conda/envs/venv/lib/python3.7/site-packages/ipykernel_launcher.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/nishit/.conda/envs/venv/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: divide by zero encountered in log\n",
      "/home/nishit/.conda/envs/venv/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in multiply\n",
      "/home/nishit/.conda/envs/venv/lib/python3.7/site-packages/ipykernel_launcher.py:20: RuntimeWarning: divide by zero encountered in log\n",
      "/home/nishit/.conda/envs/venv/lib/python3.7/site-packages/ipykernel_launcher.py:20: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.085025\n",
      "         Iterations: 50\n",
      "         Function evaluations: 101\n",
      "         Gradient evaluations: 101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nishit/.conda/envs/venv/lib/python3.7/site-packages/ipykernel_launcher.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/nishit/.conda/envs/venv/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: divide by zero encountered in log\n",
      "/home/nishit/.conda/envs/venv/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in multiply\n",
      "/home/nishit/.conda/envs/venv/lib/python3.7/site-packages/ipykernel_launcher.py:20: RuntimeWarning: divide by zero encountered in log\n",
      "/home/nishit/.conda/envs/venv/lib/python3.7/site-packages/ipykernel_launcher.py:20: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.040881\n",
      "         Iterations: 50\n",
      "         Function evaluations: 102\n",
      "         Gradient evaluations: 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nishit/.conda/envs/venv/lib/python3.7/site-packages/ipykernel_launcher.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/nishit/.conda/envs/venv/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: divide by zero encountered in log\n",
      "/home/nishit/.conda/envs/venv/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in multiply\n",
      "/home/nishit/.conda/envs/venv/lib/python3.7/site-packages/ipykernel_launcher.py:20: RuntimeWarning: divide by zero encountered in log\n",
      "/home/nishit/.conda/envs/venv/lib/python3.7/site-packages/ipykernel_launcher.py:20: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.046060\n",
      "         Iterations: 50\n",
      "         Function evaluations: 98\n",
      "         Gradient evaluations: 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nishit/.conda/envs/venv/lib/python3.7/site-packages/ipykernel_launcher.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/nishit/.conda/envs/venv/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: divide by zero encountered in log\n",
      "/home/nishit/.conda/envs/venv/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in multiply\n",
      "/home/nishit/.conda/envs/venv/lib/python3.7/site-packages/ipykernel_launcher.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/nishit/.conda/envs/venv/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: divide by zero encountered in log\n",
      "/home/nishit/.conda/envs/venv/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.693147\n",
      "         Iterations: 0\n",
      "         Function evaluations: 20\n",
      "         Gradient evaluations: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nishit/.conda/envs/venv/lib/python3.7/site-packages/ipykernel_launcher.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/nishit/.conda/envs/venv/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: divide by zero encountered in log\n",
      "/home/nishit/.conda/envs/venv/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.109819\n",
      "         Iterations: 50\n",
      "         Function evaluations: 97\n",
      "         Gradient evaluations: 97\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "79.38499999999999"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import scipy.optimize as opt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = X_tr\n",
    "y = y_tr\n",
    "        \n",
    "m = len(y)\n",
    "ones = np.ones((m,1))\n",
    "X = np.hstack((ones, X)) #add the intercept\n",
    "(m,n) = X.shape\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "def costFunctionReg(theta, X, y, lmbda):\n",
    "    m = len(y)\n",
    "    temp1 = np.multiply(y, np.log(sigmoid(np.dot(X, theta))))\n",
    "    temp2 = np.multiply(1-y, np.log(1-sigmoid(np.dot(X, theta))))\n",
    "    return np.sum(temp1 + temp2) / (-m) + np.sum(theta[1:]**2) * lmbda / (2*m)\n",
    "\n",
    "def gradRegularization(theta, X, y, lmbda):\n",
    "    m = len(y)\n",
    "    temp = sigmoid(np.dot(X, theta)) - y\n",
    "    temp = np.dot(temp.T, X).T / m + theta * lmbda / m\n",
    "    temp[0] = temp[0] - theta[0] * lmbda / m\n",
    "    return temp\n",
    "\n",
    "lmbda = 0.1\n",
    "k = 10\n",
    "theta = np.zeros((k,n)) #inital parameters\n",
    "for i in range(k):\n",
    "    digit_class = i if i else 10\n",
    "    theta[i] = opt.fmin_cg(f = costFunctionReg, x0 = theta[i],  fprime = gradRegularization, args = (X, (y == digit_class).values.flatten(), lmbda), maxiter = 50)\n",
    "    \n",
    "pred = np.argmax(X @ theta.T, axis = 1)\n",
    "pred = [e if e else 10 for e in pred]\n",
    "np.mean(pred == y.values.flatten()) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 3 (Random Classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9416"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv('mnist_train.csv')\n",
    "L = np.sqrt(784)\n",
    "X = data.iloc[:, 1:]\n",
    "y = data['label']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(n_jobs=-1, n_estimators=10)\n",
    "\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "rfc.score(X_test, y_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 4 (Decision Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modle 5 (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/nishit/.conda/envs/venv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/nishit/.conda/envs/venv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/nishit/.conda/envs/venv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/nishit/.conda/envs/venv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/nishit/.conda/envs/venv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/nishit/.conda/envs/venv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/nishit/.conda/envs/venv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/nishit/.conda/envs/venv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/nishit/.conda/envs/venv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/nishit/.conda/envs/venv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/nishit/.conda/envs/venv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/nishit/.conda/envs/venv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import cv2 as cv\n",
    "\n",
    "from keras.layers import Conv2D, Input, LeakyReLU, Dense, Activation, Flatten, Dropout, MaxPool2D\n",
    "from keras import models\n",
    "from keras.optimizers import Adam,RMSprop \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1) # seed\n",
    "df_train = pd.read_csv('mnist_train.csv')\n",
    "df_train = df_train.iloc[np.random.permutation(len(df_train))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 785)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = df_train.shape[0] # Training set size\n",
    "validation_size = int(df_train.shape[0]*0.1) # Validation set size \n",
    "\n",
    "# train_x and train_y\n",
    "train_x = np.asarray(df_train.iloc[:sample_size-validation_size,1:]).reshape([sample_size-validation_size,28,28,1]) # taking all columns expect column 0\n",
    "train_y = np.asarray(df_train.iloc[:sample_size-validation_size,0]).reshape([sample_size-validation_size,1]) # taking column 0\n",
    "\n",
    "# val_x and val_y\n",
    "val_x = np.asarray(df_train.iloc[sample_size-validation_size:,1:]).reshape([validation_size,28,28,1])\n",
    "val_y = np.asarray(df_train.iloc[sample_size-validation_size:,0]).reshape([validation_size,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((54000, 28, 28, 1), (54000, 1))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape,train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x/255\n",
    "val_x = val_x/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/nishit/.conda/envs/venv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Block 1\n",
    "model.add(Conv2D(32,3, padding  =\"same\",input_shape=(28,28,1)))\n",
    "model.add(LeakyReLU())\n",
    "model.add(Conv2D(32,3, padding  =\"same\"))\n",
    "model.add(LeakyReLU())\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Block 2\n",
    "model.add(Conv2D(64,3, padding  =\"same\"))\n",
    "model.add(LeakyReLU())\n",
    "model.add(Conv2D(64,3, padding  =\"same\"))\n",
    "model.add(LeakyReLU())\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dense(10,activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               803072    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 876,618\n",
      "Trainable params: 876,618\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "initial_lr = 0.001\n",
    "loss = \"sparse_categorical_crossentropy\"\n",
    "model.compile(Adam(lr=initial_lr), loss=loss ,metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/nishit/.conda/envs/venv/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/nishit/.conda/envs/venv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/20\n",
      "54000/54000 [==============================] - 93s 2ms/step - loss: 0.3342 - accuracy: 0.8950 - val_loss: 0.0883 - val_accuracy: 0.9742\n",
      "Epoch 2/20\n",
      "54000/54000 [==============================] - 92s 2ms/step - loss: 0.0804 - accuracy: 0.9756 - val_loss: 0.0556 - val_accuracy: 0.9833\n",
      "Epoch 3/20\n",
      "54000/54000 [==============================] - 121s 2ms/step - loss: 0.0558 - accuracy: 0.9826 - val_loss: 0.0413 - val_accuracy: 0.9878\n",
      "Epoch 4/20\n",
      "54000/54000 [==============================] - 153s 3ms/step - loss: 0.0406 - accuracy: 0.9874 - val_loss: 0.0391 - val_accuracy: 0.9887\n",
      "Epoch 5/20\n",
      "54000/54000 [==============================] - 154s 3ms/step - loss: 0.0362 - accuracy: 0.9884 - val_loss: 0.0416 - val_accuracy: 0.9890\n",
      "Epoch 6/20\n",
      "54000/54000 [==============================] - 91s 2ms/step - loss: 0.0291 - accuracy: 0.9904 - val_loss: 0.0317 - val_accuracy: 0.9903\n",
      "Epoch 7/20\n",
      "54000/54000 [==============================] - 143s 3ms/step - loss: 0.0252 - accuracy: 0.9915 - val_loss: 0.0355 - val_accuracy: 0.9910\n",
      "Epoch 8/20\n",
      "54000/54000 [==============================] - 224s 4ms/step - loss: 0.0201 - accuracy: 0.9933 - val_loss: 0.0376 - val_accuracy: 0.9887\n",
      "Epoch 9/20\n",
      "54000/54000 [==============================] - 151s 3ms/step - loss: 0.0197 - accuracy: 0.9935 - val_loss: 0.0387 - val_accuracy: 0.9890\n",
      "Epoch 10/20\n",
      "54000/54000 [==============================] - 144s 3ms/step - loss: 0.0167 - accuracy: 0.9950 - val_loss: 0.0398 - val_accuracy: 0.9900\n",
      "Epoch 11/20\n",
      "54000/54000 [==============================] - 134s 2ms/step - loss: 0.0156 - accuracy: 0.9951 - val_loss: 0.0342 - val_accuracy: 0.9922\n",
      "Epoch 12/20\n",
      "54000/54000 [==============================] - 141s 3ms/step - loss: 0.0132 - accuracy: 0.9957 - val_loss: 0.0361 - val_accuracy: 0.9912\n",
      "Epoch 13/20\n",
      "54000/54000 [==============================] - 145s 3ms/step - loss: 0.0132 - accuracy: 0.9957 - val_loss: 0.0377 - val_accuracy: 0.9908\n",
      "Epoch 14/20\n",
      "54000/54000 [==============================] - 120s 2ms/step - loss: 0.0124 - accuracy: 0.9961 - val_loss: 0.0341 - val_accuracy: 0.9913\n",
      "Epoch 15/20\n",
      "54000/54000 [==============================] - 119s 2ms/step - loss: 0.0125 - accuracy: 0.9959 - val_loss: 0.0342 - val_accuracy: 0.9927\n",
      "Epoch 16/20\n",
      "54000/54000 [==============================] - 124s 2ms/step - loss: 0.0125 - accuracy: 0.9958 - val_loss: 0.0390 - val_accuracy: 0.9910\n",
      "Epoch 17/20\n",
      "54000/54000 [==============================] - 121s 2ms/step - loss: 0.0122 - accuracy: 0.9960 - val_loss: 0.0422 - val_accuracy: 0.9897\n",
      "Epoch 18/20\n",
      "54000/54000 [==============================] - 125s 2ms/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 0.0493 - val_accuracy: 0.9903\n",
      "Epoch 19/20\n",
      "54000/54000 [==============================] - 122s 2ms/step - loss: 0.0095 - accuracy: 0.9966 - val_loss: 0.0481 - val_accuracy: 0.9898\n",
      "Epoch 20/20\n",
      "54000/54000 [==============================] - 117s 2ms/step - loss: 0.0082 - accuracy: 0.9972 - val_loss: 0.0390 - val_accuracy: 0.9907\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "batch_size = 256\n",
    "history_1 = model.fit(train_x,train_y,batch_size=batch_size,epochs=epochs,validation_data=[val_x,val_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "mnist_train = pd.read_csv('mnist_train.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = mnist_train.drop(labels = [\"label\"],axis = 1) \n",
    "y_train = mnist_train[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = mnist_test.drop(labels = [\"label\"],axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.values.reshape(-1,28,28,1)\n",
    "X_train = X_train.values.reshape(-1,28,28,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.1, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/nishit/.conda/envs/venv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (28,28,1)))\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/20\n",
      " - 185s - loss: 0.0863 - accuracy: 0.9745 - val_loss: 0.0373 - val_accuracy: 0.9887\n",
      "Epoch 2/20\n",
      " - 188s - loss: 0.0556 - accuracy: 0.9834 - val_loss: 0.0341 - val_accuracy: 0.9912\n",
      "Epoch 3/20\n",
      " - 146s - loss: 0.0447 - accuracy: 0.9864 - val_loss: 0.0332 - val_accuracy: 0.9903\n",
      "Epoch 4/20\n",
      " - 146s - loss: 0.0403 - accuracy: 0.9881 - val_loss: 0.0302 - val_accuracy: 0.9908\n",
      "Epoch 5/20\n",
      " - 144s - loss: 0.0351 - accuracy: 0.9899 - val_loss: 0.0392 - val_accuracy: 0.9897\n",
      "Epoch 6/20\n",
      " - 142s - loss: 0.0343 - accuracy: 0.9899 - val_loss: 0.0282 - val_accuracy: 0.9912\n",
      "Epoch 7/20\n",
      " - 141s - loss: 0.0331 - accuracy: 0.9909 - val_loss: 0.0308 - val_accuracy: 0.9923\n",
      "Epoch 8/20\n",
      " - 140s - loss: 0.0307 - accuracy: 0.9911 - val_loss: 0.0300 - val_accuracy: 0.9923\n",
      "Epoch 9/20\n",
      " - 142s - loss: 0.0326 - accuracy: 0.9911 - val_loss: 0.0281 - val_accuracy: 0.9932\n",
      "Epoch 10/20\n",
      " - 141s - loss: 0.0319 - accuracy: 0.9916 - val_loss: 0.0303 - val_accuracy: 0.9925\n",
      "Epoch 11/20\n",
      " - 140s - loss: 0.0345 - accuracy: 0.9910 - val_loss: 0.0258 - val_accuracy: 0.9945\n",
      "Epoch 12/20\n",
      " - 140s - loss: 0.0355 - accuracy: 0.9905 - val_loss: 0.0256 - val_accuracy: 0.9950\n",
      "Epoch 13/20\n",
      " - 147s - loss: 0.0338 - accuracy: 0.9907 - val_loss: 0.0284 - val_accuracy: 0.9937\n",
      "Epoch 14/20\n",
      " - 141s - loss: 0.0368 - accuracy: 0.9905 - val_loss: 0.0264 - val_accuracy: 0.9935\n",
      "Epoch 15/20\n",
      " - 141s - loss: 0.0334 - accuracy: 0.9915 - val_loss: 0.0439 - val_accuracy: 0.9898\n",
      "Epoch 16/20\n",
      " - 141s - loss: 0.0375 - accuracy: 0.9903 - val_loss: 0.0315 - val_accuracy: 0.9922\n",
      "Epoch 17/20\n",
      " - 143s - loss: 0.0388 - accuracy: 0.9904 - val_loss: 0.0364 - val_accuracy: 0.9925\n",
      "Epoch 18/20\n",
      " - 141s - loss: 0.0425 - accuracy: 0.9901 - val_loss: 0.0445 - val_accuracy: 0.9895\n",
      "Epoch 19/20\n",
      " - 141s - loss: 0.0432 - accuracy: 0.9894 - val_loss: 0.0399 - val_accuracy: 0.9890\n",
      "Epoch 20/20\n",
      " - 139s - loss: 0.0407 - accuracy: 0.9903 - val_loss: 0.0363 - val_accuracy: 0.9918\n"
     ]
    }
   ],
   "source": [
    "batch_size = 86\n",
    "\n",
    "history = model.fit(X_train,y_train, batch_size = batch_size, epochs = 20, validation_data = (X_val,y_val),verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
